{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31eef82ff3774d61989e794fcf65168a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87210eabbc9e405aa970527fb9585a6a",
              "IPY_MODEL_5960c8a73dfb4f8ca649f4ca88207bb0",
              "IPY_MODEL_87266a8cd44143d0b432cdc51362b8bf"
            ],
            "layout": "IPY_MODEL_f752de2191c54b12bd0164576ce2b19d"
          }
        },
        "87210eabbc9e405aa970527fb9585a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c02abf3a181c4abba6e411fcb09a87f6",
            "placeholder": "​",
            "style": "IPY_MODEL_6500984d753a4dac947dc3d2d8cd1820",
            "value": "Batches: 100%"
          }
        },
        "5960c8a73dfb4f8ca649f4ca88207bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5850709939475e86aa3aa042c26850",
            "max": 305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb3a2c00b2064746be07c7f4525c6038",
            "value": 305
          }
        },
        "87266a8cd44143d0b432cdc51362b8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc5441b54ab34085a8d968aa4bd74db2",
            "placeholder": "​",
            "style": "IPY_MODEL_0322251143a941ed9417bf885f6c37d6",
            "value": " 305/305 [00:02&lt;00:00, 142.81it/s]"
          }
        },
        "f752de2191c54b12bd0164576ce2b19d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02abf3a181c4abba6e411fcb09a87f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6500984d753a4dac947dc3d2d8cd1820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e5850709939475e86aa3aa042c26850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3a2c00b2064746be07c7f4525c6038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc5441b54ab34085a8d968aa4bd74db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0322251143a941ed9417bf885f6c37d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielosullivan2007/graphs/blob/main/Link_Regression_on_Movielens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MovieLens Rating Prediction Workshop Notebook\n",
        "\n",
        "This notebook runs faster on a GPU runtime. To enable it, go to Edit > Notebook Settings > Hardware Accelerator > GPU.\n"
      ],
      "metadata": {
        "id": "Ptk1J307IVn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "PqYLHVWoIgSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from fuzzywuzzy import fuzz\n",
        "import os\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "id": "IKXgOkl6Iabv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad3ed32-ecd8-46b5-ccb6-f542505c4329"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "!pip install sentence_transformers\n",
        "!pip3 install fuzzywuzzy[speedup]\n",
        "!pip install captum"
      ],
      "metadata": {
        "id": "pV0Rkm6tIqcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64da063a-9d4f-4d29-e1b5-2ab7c14be6e0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/nightly/torch-2.1.0+cu121.html\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.10/dist-packages (0.3.1.dev20231225+pt21cu121)\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-dqc1bs4a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-dqc1bs4a\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 0e526ab546b135dd8d5fbd55174d74da1e4028be\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.2.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: fuzzywuzzy[speedup] in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-levenshtein>=0.12 in /usr/local/lib/python3.10/dist-packages (from fuzzywuzzy[speedup]) (0.23.0)\n",
            "Requirement already satisfied: Levenshtein==0.23.0 in /usr/local/lib/python3.10/dist-packages (from python-levenshtein>=0.12->fuzzywuzzy[speedup]) (0.23.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.23.0->python-levenshtein>=0.12->fuzzywuzzy[speedup]) (3.5.2)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link Regression on the MovieLens Dataset\n",
        "\n",
        "This notebook shows how to load a set of `*.csv` files into a `torch_geometric.data.HeteroData` object and how to train a [heterogeneous graph model](https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html#hgtutorial).\n",
        "\n",
        "We are going to use the [Movielens dataset](https://grouplens.org/datasets/movielens/), which is collected by the GroupLens Research group. The toy dataset describes movies, users, and their ratings. We are going to predict the rating of a user for a movie."
      ],
      "metadata": {
        "id": "1WJ8piSnIy2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Ingestion"
      ],
      "metadata": {
        "id": "51OK1cQL9V9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset_name = 'ml-latest-small'\n",
        "\n",
        "url = f'https://files.grouplens.org/datasets/movielens/{dataset_name}.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movies_path = f'./{dataset_name}/movies.csv'\n",
        "ratings_path = f'./{dataset_name}/ratings.csv'"
      ],
      "metadata": {
        "id": "EjJrBa3J0btD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354cd2a0-cd80-4275-9863-0001a08be3bc"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using existing file ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire ratings dataframe into memory:\n",
        "ratings_df = pd.read_csv(ratings_path)[[\"userId\", \"movieId\", \"rating\"]]\n",
        "\n",
        "# Load the entire movie dataframe into memory:\n",
        "movies_df = pd.read_csv(movies_path, index_col='movieId')\n",
        "\n",
        "print('movies.csv:')\n",
        "print('===========')\n",
        "print(movies_df[[\"genres\", \"title\"]].head())\n",
        "print(f\"Number of movies: {len(movies_df)}\")\n",
        "print()\n",
        "print('ratings.csv:')\n",
        "print('============')\n",
        "print(ratings_df[[\"userId\", \"movieId\", \"rating\"]].head())\n",
        "print(f\"Number of ratings: {len(ratings_df)}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "haJz-BYBI2wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1925e3f-e130-4edb-ed3f-4afb0b8fb3b7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movies.csv:\n",
            "===========\n",
            "                                              genres  \\\n",
            "movieId                                                \n",
            "1        Adventure|Animation|Children|Comedy|Fantasy   \n",
            "2                         Adventure|Children|Fantasy   \n",
            "3                                     Comedy|Romance   \n",
            "4                               Comedy|Drama|Romance   \n",
            "5                                             Comedy   \n",
            "\n",
            "                                      title  \n",
            "movieId                                      \n",
            "1                          Toy Story (1995)  \n",
            "2                            Jumanji (1995)  \n",
            "3                   Grumpier Old Men (1995)  \n",
            "4                  Waiting to Exhale (1995)  \n",
            "5        Father of the Bride Part II (1995)  \n",
            "Number of movies: 9742\n",
            "\n",
            "ratings.csv:\n",
            "============\n",
            "   userId  movieId  rating\n",
            "0       1        1     4.0\n",
            "1       1        3     4.0\n",
            "2       1        6     4.0\n",
            "3       1       47     5.0\n",
            "4       1       50     5.0\n",
            "Number of ratings: 100836\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, let's add our ratings to the dataset to get predictions for movies we haven't seen yet.\n",
        "\n",
        "There are two ways to add ratings:\n",
        "1. **Add ratings manually**\n",
        "2. **Upload IMDB ratings**\n"
      ],
      "metadata": {
        "id": "cK1yWr3uBjaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add your ratings manually\n",
        "\n",
        "\n",
        "We recommend adding at least 10 ratings. Let's first check out the most rated movies. Additional movies in the table are: *Avatar*, *The Dark Knight*, *Pretty Women*,\n",
        "*Titanic*, *The Lion King*, *Jurassic Park*, *The Matrix*, *The Lord of the Rings* and *The Avengers*. Please note that the article in the movie title is often at the end of the title."
      ],
      "metadata": {
        "id": "mOA1_3IGBqCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify your userId\n",
        "our_user_id = ratings_df['userId'].max() + 1\n",
        "\n",
        "print('Most rated movies:')\n",
        "print('==================')\n",
        "most_rated_movies = ratings_df['movieId'].value_counts().head(10)\n",
        "print(movies_df.loc[most_rated_movies.index][[\"title\"]])\n",
        "\n",
        "# Initialize your rating list\n",
        "ratings = []"
      ],
      "metadata": {
        "id": "W5rGmyzUBoW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3497848-6e41-45a6-c1b5-f00c29dd02e8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most rated movies:\n",
            "==================\n",
            "                                          title\n",
            "356                         Forrest Gump (1994)\n",
            "318            Shawshank Redemption, The (1994)\n",
            "296                         Pulp Fiction (1994)\n",
            "593            Silence of the Lambs, The (1991)\n",
            "2571                         Matrix, The (1999)\n",
            "260   Star Wars: Episode IV - A New Hope (1977)\n",
            "480                        Jurassic Park (1993)\n",
            "110                           Braveheart (1995)\n",
            "589           Terminator 2: Judgment Day (1991)\n",
            "527                     Schindler's List (1993)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your ratings here:\n",
        "num_ratings = 5\n",
        "while len(ratings) < num_ratings:\n",
        "    print(f'Select the {len(ratings) + 1}. movie:')\n",
        "    print('=====================================')\n",
        "    movie = input('Please enter the movie title: ')\n",
        "    movies_df['title_score'] = movies_df['title'].apply(lambda x: fuzz.ratio(x, movie))\n",
        "    print(movies_df.sort_values('title_score', ascending=False)[['title']].head(5))\n",
        "    movie_id = input('Please enter the movie id: ')\n",
        "    if not movie_id:\n",
        "        continue\n",
        "    movie_id = int(movie_id)\n",
        "    rating = float(input('Please enter your rating: '))\n",
        "    if not rating:\n",
        "        continue\n",
        "    assert 0 <= rating <= 5\n",
        "    ratings.append({'movieId': movie_id, 'rating': rating, 'userId': our_user_id})\n",
        "    print()"
      ],
      "metadata": {
        "id": "llcJK-CSB2q0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff0cf818-ea7e-45e4-9412-24c8a5b54cb9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select the 1. movie:\n",
            "=====================================\n",
            "Please enter the movie title: titanic\n",
            "                            title\n",
            "movieId                          \n",
            "1721               Titanic (1997)\n",
            "3404               Titanic (1953)\n",
            "4864              Titanica (1992)\n",
            "160872             Satanic (2016)\n",
            "3403     Raise the Titanic (1980)\n",
            "Please enter the movie id: 1721\n",
            "Please enter your rating: 1\n",
            "\n",
            "Select the 2. movie:\n",
            "=====================================\n",
            "Please enter the movie title: avatar\n",
            "                       title\n",
            "movieId                     \n",
            "72998          Avatar (2009)\n",
            "156605              Paterson\n",
            "110586        Calvary (2014)\n",
            "131098   Saving Santa (2013)\n",
            "4704          Hatari! (1962)\n",
            "Please enter the movie id: 72998\n",
            "Please enter your rating: 1\n",
            "\n",
            "Select the 3. movie:\n",
            "=====================================\n",
            "Please enter the movie title: Pulp Fiction\n",
            "                       title\n",
            "movieId                     \n",
            "296      Pulp Fiction (1994)\n",
            "2206        Suspicion (1941)\n",
            "2439       Affliction (1997)\n",
            "32058    Class Action (1991)\n",
            "2599         Election (1999)\n",
            "Please enter the movie id: 296\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-a219c6856904>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmovie_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please enter your rating: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDn7iioYBgDP",
        "outputId": "7ac25580-e9ce-450b-ec68-18ef5708386d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "611"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your ratings to the rating dataframe\n",
        "ratings_df = pd.concat([ratings_df, pd.DataFrame.from_records(ratings)])"
      ],
      "metadata": {
        "id": "VCR0uLeGB_xa"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload your IMDB ratings\n",
        "\n",
        "If you have an IMDB account, you can also upload your IMDB ratings. To do so, please follow the following steps:\n",
        "1. Go to https://www.imdb.com/\n",
        "2. Login to your account\n",
        "3. Go to `Your Ratings`\n",
        "4. Click on `Export Ratings` after clicking the three dots in the upper right corner\n",
        "5. Upload the downloaded `ratings.csv` file to the current directory\n",
        "6. Rename the file to `imdb_ratings.csv`\n",
        "7. Run the following cell\n"
      ],
      "metadata": {
        "id": "Vy4EpbbGCCP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select our userId\n",
        "our_user_id = ratings_df['userId'].max() + 1\n",
        "\n",
        "# Load the IMDB ratings:\n",
        "imdb_rating_path = f'./imdb_ratings.csv'\n",
        "imdb_ratings_df = pd.read_csv(imdb_rating_path)\n",
        "imdb_ratings_df.columns = imb_ratings_df.columns.str.strip().str.lower()\n",
        "\n",
        "# The IMDB movie titles / ids do not match the movie titles /ids in the movielens dataframes\n",
        "# so we need to map them:\n",
        "imdb_ratings_df['title'] = imdb_ratings_df['title'] + ' (' + imdb_ratings_df['year'].astype(str) + ')'\n",
        "imdb_ratings_df['title'] = imdb_ratings_df['title'].str.strip()\n",
        "movies_df['title'] = movies_df['title'].str.strip()\n",
        "imdb_ratings_df = imdb_ratings_df.merge(movies_df['title'].reset_index(), on='title', how='inner', )\n",
        "\n",
        "# The ratings are on a scale from 1 to 10, so we need to transform them to a scale from 0 to 5:\n",
        "imdb_ratings_df['rating'] = (imdb_ratings_df['your rating'] / 2).astype(int)\n",
        "\n",
        "# Your ratings that we are going to use:\n",
        "print('Your IMDB ratings:')\n",
        "print('==================')\n",
        "print(imdb_ratings_df[['title', 'rating']].head(10))\n",
        "\n",
        "# Finally, we can add the ratings to the ratings data frame:\n",
        "imdb_ratings_df['userId'] = our_user_id\n",
        "ratings_df = pd.concat([ratings_df, imdb_ratings_df[['movieId', 'rating', 'userId']]])"
      ],
      "metadata": {
        "id": "6x3ZJgHRB0Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "We are going to use the genre as well as the title of the movie as node features. For the `title` features, we are going to use a pre-trained [sentence transformer](https://www.sbert.net/) model to encode the title into a vector.\n",
        "For the `genre` features, we are going to use a one-hot encoding."
      ],
      "metadata": {
        "id": "0uhaQNVsI76a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# One-hot encode the genres:\n",
        "genres = movies_df['genres'].str.get_dummies('|').values\n",
        "genres = torch.from_numpy(genres).to(torch.float)\n",
        "\n",
        "# Load the pre-trained sentence transformer model and encode the movie titles:\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "with torch.no_grad():\n",
        "    titles = model.encode(movies_df['title'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
        "    titles = titles.cpu()\n",
        "\n",
        "# Concatenate the genres and title features:\n",
        "movie_features = torch.cat([genres, titles], dim=-1)\n",
        "\n",
        "# We don't have user features, which is why we use an identity matrix\n",
        "user_features = torch.eye(len(ratings_df['userId'].unique()))\n"
      ],
      "metadata": {
        "id": "fXF-BNIYJAMo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "31eef82ff3774d61989e794fcf65168a",
            "87210eabbc9e405aa970527fb9585a6a",
            "5960c8a73dfb4f8ca649f4ca88207bb0",
            "87266a8cd44143d0b432cdc51362b8bf",
            "f752de2191c54b12bd0164576ce2b19d",
            "c02abf3a181c4abba6e411fcb09a87f6",
            "6500984d753a4dac947dc3d2d8cd1820",
            "0e5850709939475e86aa3aa042c26850",
            "eb3a2c00b2064746be07c7f4525c6038",
            "cc5441b54ab34085a8d968aa4bd74db2",
            "0322251143a941ed9417bf885f6c37d6"
          ]
        },
        "outputId": "9438eaea-7c9a-443f-b11d-414077be8aa6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/305 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31eef82ff3774d61989e794fcf65168a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_features.size()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SvDryNJCIOP",
        "outputId": "a64d1ef5-3003-4dfb-dd87-55b4479c28bc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([611, 611])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ratings.csv` file contains the ratings of users for movies. From this\n",
        "file we are extracting the `userId`. We create a mapping from the `userId`\n",
        "to a unique consecutive value in the range `[0, num_users]`. This is needed as we want our final data representation to be as compact as possible, *e.g.*, the representation of a user in the first row should be accessible via `x[0]`.\n",
        "The same we do for the `movieId`.\n",
        "Afterwards, we obtain the final `edge_index` representation of shape `[2, num_ratings]` from `ratings.csv` by merging mapped user and movie indices with the raw indices given by the original data frame.\n"
      ],
      "metadata": {
        "id": "1cHyIhDgJCZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from the userId to a unique consecutive value in the range [0, num_users]:\n",
        "unique_user_id = ratings_df['userId'].unique()\n",
        "unique_user_id = pd.DataFrame(data={\n",
        "    'userId': unique_user_id,\n",
        "    'mappedUserId': pd.RangeIndex(len(unique_user_id))\n",
        "    })\n",
        "print(\"Mapping of user IDs to consecutive values:\")\n",
        "print(\"==========================================\")\n",
        "print(unique_user_id.head())\n",
        "print()\n",
        "\n",
        "# Create a mapping from the movieId to a unique consecutive value in the range [0, num_movies]:\n",
        "unique_movie_id = ratings_df['movieId'].unique()\n",
        "unique_movie_id = pd.DataFrame(data={\n",
        "    'movieId': unique_movie_id,\n",
        "    'mappedMovieId': pd.RangeIndex(len(unique_movie_id))\n",
        "    })\n",
        "print(\"Mapping of movie IDs to consecutive values:\")\n",
        "print(\"===========================================\")\n",
        "print(unique_movie_id.head())\n",
        "print()\n",
        "\n",
        "# Merge the mappings with the original data frame:\n",
        "ratings_df = ratings_df.merge(unique_user_id, on='userId')\n",
        "ratings_df = ratings_df.merge(unique_movie_id, on='movieId')\n",
        "\n",
        "# With this, we are ready to create the edge_index representation in COO format\n",
        "# following the PyTorch Geometric semantics:\n",
        "edge_index = torch.stack([\n",
        "    torch.tensor(ratings_df['mappedUserId'].values),\n",
        "    torch.tensor(ratings_df['mappedMovieId'].values)]\n",
        "    , dim=0)\n",
        "\n",
        "assert edge_index.shape == (2, len(ratings_df))\n",
        "\n",
        "print(\"Final edge indices pointing from users to movies:\")\n",
        "print(\"================================================\")\n",
        "print(edge_index[:, :10])"
      ],
      "metadata": {
        "id": "_7YZJLJVJEbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6caea7-9cf1-4bb7-a39a-12bd9f9bbbec"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of user IDs to consecutive values:\n",
            "==========================================\n",
            "   userId  mappedUserId\n",
            "0       1             0\n",
            "1       2             1\n",
            "2       3             2\n",
            "3       4             3\n",
            "4       5             4\n",
            "\n",
            "Mapping of movie IDs to consecutive values:\n",
            "===========================================\n",
            "   movieId  mappedMovieId\n",
            "0        1              0\n",
            "1        3              1\n",
            "2        6              2\n",
            "3       47              3\n",
            "4       50              4\n",
            "\n",
            "Final edge indices pointing from users to movies:\n",
            "================================================\n",
            "tensor([[ 0,  4,  6, 14, 16, 17, 18, 20, 26, 30],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heterogeneous Graph Construction\n",
        "\n",
        "With this we are ready to initialize our heterogeneous graph data object and pass the\n",
        "necessary information to it.\n",
        "\n",
        "We also take care of adding reverse edges to the `HeteroData` object. This allows our GNN\n",
        "model to use both directions of the edges for the message passing."
      ],
      "metadata": {
        "id": "HfnycIvfJHrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "# Create the heterogeneous graph data object:\n",
        "data = HeteroData()\n",
        "\n",
        "# Add the user nodes:\n",
        "data['user'].x = user_features  # [num_users, num_features_users]\n",
        "\n",
        "# Add the movie nodes:\n",
        "data['movie'].x = movie_features  # [num_movies, num_features_movies]\n",
        "\n",
        "# Add the rating edges:\n",
        "data['user', 'rates', 'movie'].edge_index = edge_index  # [2, num_ratings]\n",
        "\n",
        "# Add the rating labels:\n",
        "rating = torch.from_numpy(ratings_df['rating'].values).to(torch.float)\n",
        "data['user', 'rates', 'movie'].edge_label = rating  # [num_ratings]\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "data = T.ToUndirected()(data)\n",
        "\n",
        "# With the above transformation we also got reversed labels for the edges.\n",
        "# We are going to remove them:\n",
        "del data['movie', 'rev_rates', 'user'].edge_label\n",
        "\n",
        "assert data['user'].num_nodes == len(unique_user_id)\n",
        "assert data['user', 'rates', 'movie'].num_edges == len(ratings_df)\n",
        "assert data['movie'].num_features == 404\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "cDQaX8OPJMvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a994638d-246f-485f-b034-2d30d64ddfe9"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  user={ x=[611, 611] },\n",
              "  movie={ x=[9742, 404] },\n",
              "  (user, rates, movie)={\n",
              "    edge_index=[2, 100838],\n",
              "    edge_label=[100838],\n",
              "  },\n",
              "  (movie, rev_rates, user)={ edge_index=[2, 100838] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Splitting\n",
        "\n",
        "We can now split our data into a training, validation and test set. We are going to use\n",
        "the `T.RandomLinkSplit` transform from PyG to do this. This transform will randomly\n",
        "split the links with their label/rating into training, validation and test set.\n",
        "We are going to use 80% of the edges for training, 10% for validation and 10% for testing."
      ],
      "metadata": {
        "id": "qpcH0bniJaJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('user', 'rates', 'movie')],\n",
        "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
        ")(data)\n",
        "train_data, val_data"
      ],
      "metadata": {
        "id": "njo191z3JctD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51114644-823c-47ff-b758-f48c1cee6826"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(HeteroData(\n",
              "   user={ x=[611, 611] },\n",
              "   movie={ x=[9742, 404] },\n",
              "   (user, rates, movie)={\n",
              "     edge_index=[2, 80672],\n",
              "     edge_label=[80672],\n",
              "     edge_label_index=[2, 80672],\n",
              "   },\n",
              "   (movie, rev_rates, user)={ edge_index=[2, 80672] }\n",
              " ),\n",
              " HeteroData(\n",
              "   user={ x=[611, 611] },\n",
              "   movie={ x=[9742, 404] },\n",
              "   (user, rates, movie)={\n",
              "     edge_index=[2, 80672],\n",
              "     edge_label=[10083],\n",
              "     edge_label_index=[2, 10083],\n",
              "   },\n",
              "   (movie, rev_rates, user)={ edge_index=[2, 80672] }\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network\n",
        "\n",
        "We are now ready to define our GNN model. We are going to use a simple GNN model with\n",
        "two message passing layers for the encoding of the user and movie nodes.\n",
        "Additionally, we are going to use a decoder to predict the rating for the encoded\n",
        "user-movie combination."
      ],
      "metadata": {
        "id": "xfg4wVcNJfFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (f\"No. users: {ratings_df.userId.nunique()}\")\n",
        "print (f\"No. movies: {movies_df.index.nunique()}\")\n",
        "\n",
        "train_data.x_dict\n",
        "#, train_data.edge_index_dict,\n",
        " #                train_data['user', 'movie'].edge_label_index)\n",
        "\n",
        "print (f\"training tensor for users size: {train_data.x_dict['user'].size()}\")\n",
        "print (f\"training tensor for movies size: {train_data.x_dict['movie'].size()}\")\n",
        "\n",
        "print (f\"training tensor for user-rates-movie: {train_data.edge_index_dict[('user', 'rates', 'movie')].size()}\")\n",
        "print (f\"training tensor for edge label indices: {train_data['user', 'movie'].edge_label_index.size()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4ICEvYlTfZx",
        "outputId": "5fafce69-ce16-40e9-beae-fb6b2aa727f9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. users: 611\n",
            "No. movies: 9742\n",
            "training tensor for users size: torch.Size([611, 611])\n",
            "training tensor for movies size: torch.Size([9742, 404])\n",
            "training tensor for user-rates-movie: torch.Size([2, 80672])\n",
            "training tensor for edge label indices: torch.Size([2, 80672])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        print (x.size())\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        print (z_dict['user'].size())\n",
        "        print (z_dict['movie'].size())\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Model(hidden_channels=32).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "fl5W1gg5Jhzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ffbec4-931c-426b-d48b-3a8945cbc33a"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proxy(size)\n",
            "Model(\n",
            "  (encoder): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (user__rates__movie): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "      (movie__rev_rates__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (user__rates__movie): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "      (movie__rev_rates__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (decoder): EdgeDecoder(\n",
            "    (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (lin2): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Heterogeneous GNN\n",
        "\n",
        "Training our GNN is then similar to training any PyTorch model.\n",
        "We move the model to the desired device, and initialize an optimizer that takes care of adjusting model parameters via stochastic gradient descent.\n",
        "\n",
        "The training loop applies the forward computation of the model, computes the loss from ground-truth labels and obtained predictions, and adjusts model parameters via back-propagation and stochastic gradient descent.\n"
      ],
      "metadata": {
        "id": "azGW0k2pJoS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['user', 'movie'].edge_label_index)\n",
        "    target = train_data['user', 'movie'].edge_label\n",
        "    loss = F.mse_loss(pred, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    data = data.to(device)\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['user', 'movie'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=5)\n",
        "    target = data['user', 'movie'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)\n",
        "\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    if epoch ==1:\n",
        "        train_data = train_data.to(device)\n",
        "        loss = train()\n",
        "        train_rmse = test(train_data)\n",
        "        val_rmse = test(val_data)\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "            f'Val: {val_rmse:.4f}')"
      ],
      "metadata": {
        "id": "_5_rbeCjJnsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ba5335-f0dc-48f3-8506-ea4bfd8b078f"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([611, 32])\n",
            "torch.Size([9742, 32])\n",
            "torch.Size([611, 32])\n",
            "torch.Size([9742, 32])\n",
            "torch.Size([611, 32])\n",
            "torch.Size([9742, 32])\n",
            "Epoch: 001, Loss: 12.3541, Train: 3.2612, Val: 3.2665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "From the validation results, our model can generalize well to unseen data. The val RMSE is should be around 0.9, meaning that, on average our model is off by 0.9 stars. We can now evaluate our model on the test set and take a closer look into the predictions."
      ],
      "metadata": {
        "id": "EGP6RiiZJtU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    test_data = test_data.to(device)\n",
        "    pred = model(test_data.x_dict, test_data.edge_index_dict,\n",
        "                 test_data['user', 'movie'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=5)\n",
        "    target = test_data['user', 'movie'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    print(f'Test RMSE: {rmse:.4f}')\n",
        "\n",
        "userId = test_data['user', 'movie'].edge_label_index[0].cpu().numpy()\n",
        "movieId = test_data['user', 'movie'].edge_label_index[1].cpu().numpy()\n",
        "pred = pred.cpu().numpy()\n",
        "target = target.cpu().numpy()\n",
        "\n",
        "print(pd.DataFrame({'userId': userId, 'movieId': movieId, 'rating': pred, 'target': target}))"
      ],
      "metadata": {
        "id": "QT_NONRIJwE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "ec3c4043-4553-4756-b158-022f1e5564a6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-314d0dcf9330>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'movie'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test RMSE: {rmse:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Movie recommendations\n",
        "\n",
        "We can now use the model to generate ratings for a movie we haven't seen.\n"
      ],
      "metadata": {
        "id": "mWH_UzPYF7_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your mappedUserId\n",
        "mapped_user_id = unique_user_id[unique_user_id['userId'] == our_user_id]['mappedUserId'].values[0]\n",
        "\n",
        "# Select movies that you haven't seen before\n",
        "movies_rated = ratings_df[ratings_df['mappedUserId'] == mapped_user_id]\n",
        "movies_not_rated = movies_df[~movies_df.index.isin(movies_rated['movieId'])]\n",
        "movies_not_rated = movies_not_rated.merge(unique_movie_id, on='movieId')\n",
        "movie = movies_not_rated.sample(1)\n",
        "\n",
        "print(f\"The movie we want to predict a raiting for is:  {movie['title'].item()}\")"
      ],
      "metadata": {
        "id": "5gp3hABvCoFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96e0806-7216-4da8-920d-f83e1eda50a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie we want to predict a raiting for is:  Jack (1996)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new `edge_label_index` between the user and the movie\n",
        "edge_label_index = torch.tensor([\n",
        "    mapped_user_id,\n",
        "    movie.mappedMovieId.item()])\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_data.to(device)\n",
        "    pred = model(test_data.x_dict, test_data.edge_index_dict, edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=5).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "XYe9poFGEig6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.item()"
      ],
      "metadata": {
        "id": "GN5uxt-CD1lV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f995343d-1374-437a-cb9d-a9f478c425d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0309882164001465"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explaining the Predictions\n",
        "\n",
        "PyTorch Geometric also provides a way to explain the predictions of a GNN. Let's check which movie ratings have influenced this prediction the most.\n",
        "\n",
        "We will use the [captum](https://captum.ai/) library to explain the predictions."
      ],
      "metadata": {
        "id": "TyhTL520KFwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.explain import Explainer, CaptumExplainer\n",
        "\n",
        "explainer = Explainer(\n",
        "    model=model,\n",
        "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
        "    explanation_type='model',\n",
        "    model_config=dict(\n",
        "        mode='regression',\n",
        "        task_level='edge',\n",
        "        return_type='raw',\n",
        "    ),\n",
        "    node_mask_type=None,\n",
        "    edge_mask_type='object',\n",
        ")\n",
        "\n",
        "explanation = explainer(\n",
        "    test_data.x_dict, test_data.edge_index_dict, index=0,\n",
        "    edge_label_index=edge_label_index).cpu().detach()\n",
        "explanation"
      ],
      "metadata": {
        "id": "i1fe7gcrPNo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b601b9-dda3-4512-e4e8-26a536fbbb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroExplanation(\n",
              "  prediction=[1],\n",
              "  target=[1],\n",
              "  index=0,\n",
              "  edge_label_index=[2],\n",
              "  \u001b[1muser\u001b[0m={ x=[611, 611] },\n",
              "  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n",
              "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
              "    edge_mask=[90757],\n",
              "    edge_index=[2, 90757]\n",
              "  },\n",
              "  \u001b[1m(movie, rev_rates, user)\u001b[0m={\n",
              "    edge_mask=[90757],\n",
              "    edge_index=[2, 90757]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User to movie link + attribution\n",
        "user_to_movie = explanation['user', 'movie'].edge_index.numpy().T\n",
        "user_to_movie_attr = explanation['user', 'movie'].edge_mask.numpy().T\n",
        "user_to_movie_df = pd.DataFrame(\n",
        "    np.hstack([user_to_movie, user_to_movie_attr.reshape(-1,1)]),\n",
        "    columns = ['mappedUserId', 'mappedMovieId', 'attr']\n",
        ")\n",
        "\n",
        "# Movie to user link + attribution\n",
        "movie_to_user = explanation['movie', 'user'].edge_index.numpy().T\n",
        "movie_to_user_attr = explanation[ 'movie', 'user'].edge_mask.numpy().T\n",
        "movie_to_user_df = pd.DataFrame(\n",
        "    np.hstack([movie_to_user, movie_to_user_attr.reshape(-1,1)]),\n",
        "    columns = ['mappedMovieId', 'mappedUserId','attr']\n",
        ")\n",
        "explanation_df = pd.concat([user_to_movie_df, movie_to_user_df])\n",
        "explanation_df[[\"mappedUserId\", \"mappedMovieId\"]] = explanation_df[[\"mappedUserId\", \"mappedMovieId\"]].astype(int)\n",
        "\n",
        "print(f\"Attribtion for all edges towards prediction of movie rating of movie:\\n {movie['title'].item()}\")\n",
        "print(\"==========================================================================================\")\n",
        "print(explanation_df.sort_values(by='attr'))"
      ],
      "metadata": {
        "id": "3YIoR6LOGLa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76880aa6-2c64-4c06-8f7c-3f92ff37024d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attribtion for all edges towards prediction of movie rating of movie:\n",
            " Jack (1996)\n",
            "==========================================================================================\n",
            "       mappedUserId  mappedMovieId      attr\n",
            "57723           275            690 -0.012362\n",
            "3848              5            690 -0.011254\n",
            "71472           491            690 -0.010652\n",
            "30759           150            690 -0.009278\n",
            "69702           216            690 -0.006919\n",
            "...             ...            ...       ...\n",
            "60076           610             28  0.036200\n",
            "81322           567            690  0.046985\n",
            "31685           610            166  0.047016\n",
            "76142           610             26  0.049234\n",
            "28134           610             20  0.054034\n",
            "\n",
            "[181514 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select links that connect to our user\n",
        "explanation_df = explanation_df[explanation_df['mappedUserId'] == mapped_user_id]\n",
        "\n",
        "# We group the attribution scores by movie\n",
        "explanation_df = explanation_df.groupby('mappedMovieId').sum()\n",
        "\n",
        "# Merge with movies_df to receive title\n",
        "# But first, we need to add the original id\n",
        "explanation_df = explanation_df.merge(unique_movie_id, on='mappedMovieId')\n",
        "explanation_df = explanation_df.merge(movies_df, on='movieId')\n",
        "\n",
        "pd.options.display.float_format = \"{:,.9f}\".format\n",
        "\n",
        "print(\"Top movies that influenced the prediction:\")\n",
        "print(\"==============================================\")\n",
        "print(explanation_df.sort_values(by='attr', ascending=False, key= lambda x: abs(x))[['title', 'attr']].head())"
      ],
      "metadata": {
        "id": "8yN6svXQKe7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024cf794-4c94-4bbd-e39a-33fe7b59c446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top movies that influenced the prediction:\n",
            "==============================================\n",
            "                     title        attr\n",
            "0      Forrest Gump (1994) 0.054058370\n",
            "1     Jurassic Park (1993) 0.049267028\n",
            "3       Matrix, The (1999) 0.047048138\n",
            "2  Schindler's List (1993) 0.036232221\n"
          ]
        }
      ]
    }
  ]
}