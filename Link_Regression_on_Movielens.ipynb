{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "893982dfec004e879d2399c5947ef046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b0f0358f00c419f9788f9721dfe8f94",
              "IPY_MODEL_d0ba36a075494a3eacdeaefbb9a0cb28",
              "IPY_MODEL_9dd86c8cbb8e4de894ef8a546c30e4fc"
            ],
            "layout": "IPY_MODEL_79daadf604d94365be8e88759264aa50"
          }
        },
        "1b0f0358f00c419f9788f9721dfe8f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c293c10e37422bb1120c35a68d134f",
            "placeholder": "​",
            "style": "IPY_MODEL_95963810003441079f69eef8e6710463",
            "value": "Batches: 100%"
          }
        },
        "d0ba36a075494a3eacdeaefbb9a0cb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c2504b8f3bb4bda86c16159567d6599",
            "max": 305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbe60801657d4de1bf0c6b881914fc57",
            "value": 305
          }
        },
        "9dd86c8cbb8e4de894ef8a546c30e4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbae558e37e24d08ac51011cc4ba3aaf",
            "placeholder": "​",
            "style": "IPY_MODEL_ff14f884db1e4e3884b961b32dd21369",
            "value": " 305/305 [00:03&lt;00:00, 139.46it/s]"
          }
        },
        "79daadf604d94365be8e88759264aa50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c293c10e37422bb1120c35a68d134f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95963810003441079f69eef8e6710463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c2504b8f3bb4bda86c16159567d6599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe60801657d4de1bf0c6b881914fc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbae558e37e24d08ac51011cc4ba3aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff14f884db1e4e3884b961b32dd21369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielosullivan2007/graphs/blob/main/Link_Regression_on_Movielens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MovieLens Rating Prediction Workshop Notebook\n",
        "\n",
        "This notebook runs faster on a GPU runtime. To enable it, go to Edit > Notebook Settings > Hardware Accelerator > GPU.\n"
      ],
      "metadata": {
        "id": "Ptk1J307IVn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "PqYLHVWoIgSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "id": "IKXgOkl6Iabv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e111f53-5bcd-4f1b-9f39-e67495b7153b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "import os\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "!pip install sentence_transformers\n",
        "!pip3 install fuzzywuzzy[speedup]\n",
        "!pip install captum"
      ],
      "metadata": {
        "id": "pV0Rkm6tIqcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6491743-776e-40f0-9fdc-0e8b64ab2980"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/nightly/torch-2.1.0+cu121.html\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.10/dist-packages (0.3.1.dev20231223+pt21cu121)\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-3jaiy966\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-3jaiy966\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 0317b0ce49b4bdd12fbaca5d6dd3dbb5a1282fa3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.2.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: fuzzywuzzy[speedup] in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-levenshtein>=0.12 in /usr/local/lib/python3.10/dist-packages (from fuzzywuzzy[speedup]) (0.23.0)\n",
            "Requirement already satisfied: Levenshtein==0.23.0 in /usr/local/lib/python3.10/dist-packages (from python-levenshtein>=0.12->fuzzywuzzy[speedup]) (0.23.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.23.0->python-levenshtein>=0.12->fuzzywuzzy[speedup]) (3.5.2)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->captum) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link Regression on the MovieLens Dataset\n",
        "\n",
        "This notebook shows how to load a set of `*.csv` files into a `torch_geometric.data.HeteroData` object and how to train a [heterogeneous graph model](https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html#hgtutorial).\n",
        "\n",
        "We are going to use the [Movielens dataset](https://grouplens.org/datasets/movielens/), which is collected by the GroupLens Research group. The toy dataset describes movies, users, and their ratings. We are going to predict the rating of a user for a movie."
      ],
      "metadata": {
        "id": "1WJ8piSnIy2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Ingestion"
      ],
      "metadata": {
        "id": "51OK1cQL9V9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import download_url, extract_zip\n",
        "import pandas as pd\n",
        "\n",
        "dataset_name = 'ml-latest-small'\n",
        "\n",
        "url = f'https://files.grouplens.org/datasets/movielens/{dataset_name}.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movies_path = f'./{dataset_name}/movies.csv'\n",
        "ratings_path = f'./{dataset_name}/ratings.csv'"
      ],
      "metadata": {
        "id": "EjJrBa3J0btD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d4be4e-d3eb-4994-fb0f-a0a6ded573ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using existing file ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire ratings dataframe into memory:\n",
        "ratings_df = pd.read_csv(ratings_path)[[\"userId\", \"movieId\", \"rating\"]]\n",
        "\n",
        "# Load the entire movie dataframe into memory:\n",
        "movies_df = pd.read_csv(movies_path, index_col='movieId')\n",
        "\n",
        "print('movies.csv:')\n",
        "print('===========')\n",
        "print(movies_df[[\"genres\", \"title\"]].head())\n",
        "print(f\"Number of movies: {len(movies_df)}\")\n",
        "print()\n",
        "print('ratings.csv:')\n",
        "print('============')\n",
        "print(ratings_df[[\"userId\", \"movieId\", \"rating\"]].head())\n",
        "print(f\"Number of ratings: {len(ratings_df)}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "haJz-BYBI2wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b299e9b-5032-4ab3-932b-b4d2f72827b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movies.csv:\n",
            "===========\n",
            "                                              genres  \\\n",
            "movieId                                                \n",
            "1        Adventure|Animation|Children|Comedy|Fantasy   \n",
            "2                         Adventure|Children|Fantasy   \n",
            "3                                     Comedy|Romance   \n",
            "4                               Comedy|Drama|Romance   \n",
            "5                                             Comedy   \n",
            "\n",
            "                                      title  \n",
            "movieId                                      \n",
            "1                          Toy Story (1995)  \n",
            "2                            Jumanji (1995)  \n",
            "3                   Grumpier Old Men (1995)  \n",
            "4                  Waiting to Exhale (1995)  \n",
            "5        Father of the Bride Part II (1995)  \n",
            "Number of movies: 9742\n",
            "\n",
            "ratings.csv:\n",
            "============\n",
            "   userId  movieId  rating\n",
            "0       1        1     4.0\n",
            "1       1        3     4.0\n",
            "2       1        6     4.0\n",
            "3       1       47     5.0\n",
            "4       1       50     5.0\n",
            "Number of ratings: 100836\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, let's add our ratings to the dataset to get predictions for movies we haven't seen yet.\n",
        "\n",
        "There are two ways to add ratings:\n",
        "1. **Add ratings manually**\n",
        "2. **Upload IMDB ratings**\n"
      ],
      "metadata": {
        "id": "cK1yWr3uBjaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add your ratings manually\n",
        "\n",
        "\n",
        "We recommend adding at least 10 ratings. Let's first check out the most rated movies. Additional movies in the table are: *Avatar*, *The Dark Knight*, *Pretty Women*,\n",
        "*Titanic*, *The Lion King*, *Jurassic Park*, *The Matrix*, *The Lord of the Rings* and *The Avengers*. Please note that the article in the movie title is often at the end of the title."
      ],
      "metadata": {
        "id": "mOA1_3IGBqCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "# Specify your userId\n",
        "our_user_id = ratings_df['userId'].max() + 1\n",
        "\n",
        "print('Most rated movies:')\n",
        "print('==================')\n",
        "most_rated_movies = ratings_df['movieId'].value_counts().head(10)\n",
        "print(movies_df.loc[most_rated_movies.index][[\"title\"]])\n",
        "\n",
        "# Initialize your rating list\n",
        "ratings = []"
      ],
      "metadata": {
        "id": "W5rGmyzUBoW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8a5699-c154-48b9-a934-cd6c48173510"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most rated movies:\n",
            "==================\n",
            "                                          title\n",
            "356                         Forrest Gump (1994)\n",
            "318            Shawshank Redemption, The (1994)\n",
            "296                         Pulp Fiction (1994)\n",
            "593            Silence of the Lambs, The (1991)\n",
            "2571                         Matrix, The (1999)\n",
            "260   Star Wars: Episode IV - A New Hope (1977)\n",
            "480                        Jurassic Park (1993)\n",
            "110                           Braveheart (1995)\n",
            "589           Terminator 2: Judgment Day (1991)\n",
            "527                     Schindler's List (1993)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your ratings here:\n",
        "num_ratings = 5\n",
        "while len(ratings) < num_ratings:\n",
        "    print(f'Select the {len(ratings) + 1}. movie:')\n",
        "    print('=====================================')\n",
        "    movie = input('Please enter the movie title: ')\n",
        "    movies_df['title_score'] = movies_df['title'].apply(lambda x: fuzz.ratio(x, movie))\n",
        "    print(movies_df.sort_values('title_score', ascending=False)[['title']].head(5))\n",
        "    movie_id = input('Please enter the movie id: ')\n",
        "    if not movie_id:\n",
        "        continue\n",
        "    movie_id = int(movie_id)\n",
        "    rating = float(input('Please enter your rating: '))\n",
        "    if not rating:\n",
        "        continue\n",
        "    assert 0 <= rating <= 5\n",
        "    ratings.append({'movieId': movie_id, 'rating': rating, 'userId': our_user_id})\n",
        "    print()"
      ],
      "metadata": {
        "id": "llcJK-CSB2q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de772523-0413-46fa-b492-00df3ff45614"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select the 1. movie:\n",
            "=====================================\n",
            "Please enter the movie title: Avatar\n",
            "                       title\n",
            "movieId                     \n",
            "72998          Avatar (2009)\n",
            "156605              Paterson\n",
            "30812    Aviator, The (2004)\n",
            "6573          Avanti! (1972)\n",
            "4704          Hatari! (1962)\n",
            "Please enter the movie id: 72998\n",
            "Please enter your rating: 2\n",
            "\n",
            "Select the 2. movie:\n",
            "=====================================\n",
            "Please enter the movie title: Pulp Fiction\n",
            "                       title\n",
            "movieId                     \n",
            "296      Pulp Fiction (1994)\n",
            "2206        Suspicion (1941)\n",
            "2439       Affliction (1997)\n",
            "32058    Class Action (1991)\n",
            "2599         Election (1999)\n",
            "Please enter the movie id: 296\n",
            "Please enter your rating: 5\n",
            "\n",
            "Select the 3. movie:\n",
            "=====================================\n",
            "Please enter the movie title: The Dark Knight\n",
            "                              title\n",
            "movieId                            \n",
            "58559       Dark Knight, The (2008)\n",
            "127204         The Overnight (2015)\n",
            "7219     They Drive by Night (1940)\n",
            "4899            Black Knight (2001)\n",
            "128360     The Hateful Eight (2015)\n",
            "Please enter the movie id: 58559\n",
            "Please enter your rating: 5\n",
            "\n",
            "Select the 4. movie:\n",
            "=====================================\n",
            "Please enter the movie title: Titanic\n",
            "                            title\n",
            "movieId                          \n",
            "1721               Titanic (1997)\n",
            "3404               Titanic (1953)\n",
            "4864              Titanica (1992)\n",
            "160872             Satanic (2016)\n",
            "3403     Raise the Titanic (1980)\n",
            "Please enter the movie id: 1721\n",
            "Please enter your rating: 1\n",
            "\n",
            "Select the 5. movie:\n",
            "=====================================\n",
            "Please enter the movie title: Jurassic Park\n",
            "                                         title\n",
            "movieId                                       \n",
            "480                       Jurassic Park (1993)\n",
            "4638                  Jurassic Park III (2001)\n",
            "117529                   Jurassic World (2015)\n",
            "1544     Lost World: Jurassic Park, The (1997)\n",
            "53447                     Paranoid Park (2007)\n",
            "Please enter the movie id: 480\n",
            "Please enter your rating: 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your ratings to the rating dataframe\n",
        "ratings_df = pd.concat([ratings_df, pd.DataFrame.from_records(ratings)])"
      ],
      "metadata": {
        "id": "VCR0uLeGB_xa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload your IMDB ratings\n",
        "\n",
        "If you have an IMDB account, you can also upload your IMDB ratings. To do so, please follow the following steps:\n",
        "1. Go to https://www.imdb.com/\n",
        "2. Login to your account\n",
        "3. Go to `Your Ratings`\n",
        "4. Click on `Export Ratings` after clicking the three dots in the upper right corner\n",
        "5. Upload the downloaded `ratings.csv` file to the current directory\n",
        "6. Rename the file to `imdb_ratings.csv`\n",
        "7. Run the following cell\n"
      ],
      "metadata": {
        "id": "Vy4EpbbGCCP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select our userId\n",
        "our_user_id = ratings_df['userId'].max() + 1\n",
        "\n",
        "# Load the IMDB ratings:\n",
        "imdb_rating_path = f'./imdb_ratings.csv'\n",
        "imdb_ratings_df = pd.read_csv(imdb_rating_path)\n",
        "imdb_ratings_df.columns = imdb_ratings_df.columns.str.strip().str.lower()\n",
        "\n",
        "# The IMDB movie titles / ids do not match the movie titles /ids in the movielens dataframes\n",
        "# so we need to map them:\n",
        "imdb_ratings_df['title'] = imdb_ratings_df['title'] + ' (' + imdb_ratings_df['year'].astype(str) + ')'\n",
        "imdb_ratings_df['title'] = imdb_ratings_df['title'].str.strip()\n",
        "movies_df['title'] = movies_df['title'].str.strip()\n",
        "imdb_ratings_df = imdb_ratings_df.merge(movies_df['title'].reset_index(), on='title', how='inner', )\n",
        "\n",
        "# The ratings are on a scale from 1 to 10, so we need to transform them to a scale from 0 to 5:\n",
        "imdb_ratings_df['rating'] = (imdb_ratings_df['your rating'] / 2).astype(int)\n",
        "\n",
        "# Your ratings that we are going to use:\n",
        "print('Your IMDB ratings:')\n",
        "print('==================')\n",
        "print(imdb_ratings_df[['title', 'rating']].head(10))\n",
        "\n",
        "# Finally, we can add the ratings to the ratings data frame:\n",
        "imdb_ratings_df['userId'] = our_user_id\n",
        "ratings_df = pd.concat([ratings_df, imdb_ratings_df[['movieId', 'rating', 'userId']]])"
      ],
      "metadata": {
        "id": "6x3ZJgHRB0Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "We are going to use the genre as well as the title of the movie as node features. For the `title` features, we are going to use a pre-trained [sentence transformer](https://www.sbert.net/) model to encode the title into a vector.\n",
        "For the `genre` features, we are going to use a one-hot encoding."
      ],
      "metadata": {
        "id": "0uhaQNVsI76a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# One-hot encode the genres:\n",
        "genres = movies_df['genres'].str.get_dummies('|').values\n",
        "genres = torch.from_numpy(genres).to(torch.float)\n",
        "\n",
        "# Load the pre-trained sentence transformer model and encode the movie titles:\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "with torch.no_grad():\n",
        "    titles = model.encode(movies_df['title'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
        "    titles = titles.cpu()\n",
        "\n",
        "# Concatenate the genres and title features:\n",
        "movie_features = torch.cat([genres, titles], dim=-1)\n",
        "\n",
        "# We don't have user features, which is why we use an identity matrix\n",
        "user_features = torch.eye(len(ratings_df['userId'].unique()))\n"
      ],
      "metadata": {
        "id": "fXF-BNIYJAMo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "893982dfec004e879d2399c5947ef046",
            "1b0f0358f00c419f9788f9721dfe8f94",
            "d0ba36a075494a3eacdeaefbb9a0cb28",
            "9dd86c8cbb8e4de894ef8a546c30e4fc",
            "79daadf604d94365be8e88759264aa50",
            "a1c293c10e37422bb1120c35a68d134f",
            "95963810003441079f69eef8e6710463",
            "1c2504b8f3bb4bda86c16159567d6599",
            "bbe60801657d4de1bf0c6b881914fc57",
            "bbae558e37e24d08ac51011cc4ba3aaf",
            "ff14f884db1e4e3884b961b32dd21369"
          ]
        },
        "outputId": "e44bbad8-aabe-41f5-a161-7f32df33aee9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/305 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "893982dfec004e879d2399c5947ef046"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ratings.csv` file contains the ratings of users for movies. From this\n",
        "file we are extracting the `userId`. We create a mapping from the `userId`\n",
        "to a unique consecutive value in the range `[0, num_users]`. This is needed as we want our final data representation to be as compact as possible, *e.g.*, the representation of a user in the first row should be accessible via `x[0]`.\n",
        "The same we do for the `movieId`.\n",
        "Afterwards, we obtain the final `edge_index` representation of shape `[2, num_ratings]` from `ratings.csv` by merging mapped user and movie indices with the raw indices given by the original data frame.\n"
      ],
      "metadata": {
        "id": "1cHyIhDgJCZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from the userId to a unique consecutive value in the range [0, num_users]:\n",
        "unique_user_id = ratings_df['userId'].unique()\n",
        "unique_user_id = pd.DataFrame(data={\n",
        "    'userId': unique_user_id,\n",
        "    'mappedUserId': pd.RangeIndex(len(unique_user_id))\n",
        "    })\n",
        "print(\"Mapping of user IDs to consecutive values:\")\n",
        "print(\"==========================================\")\n",
        "print(unique_user_id.head())\n",
        "print()\n",
        "\n",
        "# Create a mapping from the movieId to a unique consecutive value in the range [0, num_movies]:\n",
        "unique_movie_id = ratings_df['movieId'].unique()\n",
        "unique_movie_id = pd.DataFrame(data={\n",
        "    'movieId': unique_movie_id,\n",
        "    'mappedMovieId': pd.RangeIndex(len(unique_movie_id))\n",
        "    })\n",
        "print(\"Mapping of movie IDs to consecutive values:\")\n",
        "print(\"===========================================\")\n",
        "print(unique_movie_id.head())\n",
        "print()\n",
        "\n",
        "# Merge the mappings with the original data frame:\n",
        "ratings_df = ratings_df.merge(unique_user_id, on='userId')\n",
        "ratings_df = ratings_df.merge(unique_movie_id, on='movieId')\n",
        "\n",
        "# With this, we are ready to create the edge_index representation in COO format\n",
        "# following the PyTorch Geometric semantics:\n",
        "edge_index = torch.stack([\n",
        "    torch.tensor(ratings_df['mappedUserId'].values),\n",
        "    torch.tensor(ratings_df['mappedMovieId'].values)]\n",
        "    , dim=0)\n",
        "\n",
        "assert edge_index.shape == (2, len(ratings_df))\n",
        "\n",
        "print(\"Final edge indices pointing from users to movies:\")\n",
        "print(\"================================================\")\n",
        "print(edge_index[:, :10])"
      ],
      "metadata": {
        "id": "_7YZJLJVJEbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54538591-5baf-4beb-ce55-f2bafd4cfc7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of user IDs to consecutive values:\n",
            "==========================================\n",
            "   userId  mappedUserId\n",
            "0       1             0\n",
            "1       2             1\n",
            "2       3             2\n",
            "3       4             3\n",
            "4       5             4\n",
            "\n",
            "Mapping of movie IDs to consecutive values:\n",
            "===========================================\n",
            "   movieId  mappedMovieId\n",
            "0        1              0\n",
            "1        3              1\n",
            "2        6              2\n",
            "3       47              3\n",
            "4       50              4\n",
            "\n",
            "Final edge indices pointing from users to movies:\n",
            "================================================\n",
            "tensor([[ 0,  4,  6, 14, 16, 17, 18, 20, 26, 30],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heterogeneous Graph Construction\n",
        "\n",
        "With this we are ready to initialize our heterogeneous graph data object and pass the\n",
        "necessary information to it.\n",
        "\n",
        "We also take care of adding reverse edges to the `HeteroData` object. This allows our GNN\n",
        "model to use both directions of the edges for the message passing."
      ],
      "metadata": {
        "id": "HfnycIvfJHrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "# Create the heterogeneous graph data object:\n",
        "data = HeteroData()\n",
        "\n",
        "# Add the user nodes:\n",
        "data['user'].x = user_features  # [num_users, num_features_users]\n",
        "\n",
        "# Add the movie nodes:\n",
        "data['movie'].x = movie_features  # [num_movies, num_features_movies]\n",
        "\n",
        "# Add the rating edges:\n",
        "data['user', 'rates', 'movie'].edge_index = edge_index  # [2, num_ratings]\n",
        "\n",
        "# Add the rating labels:\n",
        "rating = torch.from_numpy(ratings_df['rating'].values).to(torch.float)\n",
        "data['user', 'rates', 'movie'].edge_label = rating  # [num_ratings]\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "data = T.ToUndirected()(data)\n",
        "\n",
        "# With the above transformation we also got reversed labels for the edges.\n",
        "# We are going to remove them:\n",
        "del data['movie', 'rev_rates', 'user'].edge_label\n",
        "\n",
        "assert data['user'].num_nodes == len(unique_user_id)\n",
        "assert data['user', 'rates', 'movie'].num_edges == len(ratings_df)\n",
        "assert data['movie'].num_features == 404\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "cDQaX8OPJMvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3936aa6-3bfb-4281-dbfb-0de004835c76"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  user={ x=[611, 611] },\n",
              "  movie={ x=[9742, 404] },\n",
              "  (user, rates, movie)={\n",
              "    edge_index=[2, 100841],\n",
              "    edge_label=[100841],\n",
              "  },\n",
              "  (movie, rev_rates, user)={ edge_index=[2, 100841] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Splitting\n",
        "\n",
        "We can now split our data into a training, validation and test set. We are going to use\n",
        "the `T.RandomLinkSplit` transform from PyG to do this. This transform will randomly\n",
        "split the links with their label/rating into training, validation and test set.\n",
        "We are going to use 80% of the edges for training, 10% for validation and 10% for testing."
      ],
      "metadata": {
        "id": "qpcH0bniJaJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('user', 'rates', 'movie')],\n",
        "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
        ")(data)\n",
        "train_data, val_data"
      ],
      "metadata": {
        "id": "njo191z3JctD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bade4a2-8633-473d-9bde-8e78af86290d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(HeteroData(\n",
              "   user={ x=[611, 611] },\n",
              "   movie={ x=[9742, 404] },\n",
              "   (user, rates, movie)={\n",
              "     edge_index=[2, 80673],\n",
              "     edge_label=[80673],\n",
              "     edge_label_index=[2, 80673],\n",
              "   },\n",
              "   (movie, rev_rates, user)={ edge_index=[2, 80673] }\n",
              " ),\n",
              " HeteroData(\n",
              "   user={ x=[611, 611] },\n",
              "   movie={ x=[9742, 404] },\n",
              "   (user, rates, movie)={\n",
              "     edge_index=[2, 80673],\n",
              "     edge_label=[10084],\n",
              "     edge_label_index=[2, 10084],\n",
              "   },\n",
              "   (movie, rev_rates, user)={ edge_index=[2, 80673] }\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network\n",
        "\n",
        "We are now ready to define our GNN model. We are going to use a simple GNN model with\n",
        "two message passing layers for the encoding of the user and movie nodes.\n",
        "Additionally, we are going to use a decoder to predict the rating for the encoded\n",
        "user-movie combination."
      ],
      "metadata": {
        "id": "xfg4wVcNJfFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['user'][row], z_dict['movie'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Model(hidden_channels=32).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "fl5W1gg5Jhzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b95404-a98b-4f7d-f3da-4893693528d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (encoder): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (user__rates__movie): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "      (movie__rev_rates__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (user__rates__movie): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "      (movie__rev_rates__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (decoder): EdgeDecoder(\n",
            "    (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (lin2): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Heterogeneous GNN\n",
        "\n",
        "Training our GNN is then similar to training any PyTorch model.\n",
        "We move the model to the desired device, and initialize an optimizer that takes care of adjusting model parameters via stochastic gradient descent.\n",
        "\n",
        "The training loop applies the forward computation of the model, computes the loss from ground-truth labels and obtained predictions, and adjusts model parameters via back-propagation and stochastic gradient descent.\n"
      ],
      "metadata": {
        "id": "azGW0k2pJoS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['user', 'movie'].edge_label_index)\n",
        "    target = train_data['user', 'movie'].edge_label\n",
        "    loss = F.mse_loss(pred, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    data = data.to(device)\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['user', 'movie'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=5)\n",
        "    target = data['user', 'movie'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)\n",
        "\n",
        "\n",
        "for epoch in range(1, 301):\n",
        "    train_data = train_data.to(device)\n",
        "    loss = train()\n",
        "    train_rmse = test(train_data)\n",
        "    val_rmse = test(val_data)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "          f'Val: {val_rmse:.4f}')"
      ],
      "metadata": {
        "id": "_5_rbeCjJnsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efca12d-86f9-4480-8836-335e1bc8cf93"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 14.1536, Train: 3.5652, Val: 3.5757\n",
            "Epoch: 002, Loss: 12.7105, Train: 3.2699, Val: 3.2818\n",
            "Epoch: 003, Loss: 10.6920, Train: 2.7271, Val: 2.7422\n",
            "Epoch: 004, Loss: 7.4369, Train: 1.8207, Val: 1.8399\n",
            "Epoch: 005, Loss: 3.3150, Train: 1.0689, Val: 1.0608\n",
            "Epoch: 006, Loss: 1.1425, Train: 1.8242, Val: 1.7895\n",
            "Epoch: 007, Loss: 5.5669, Train: 1.7728, Val: 1.7368\n",
            "Epoch: 008, Loss: 3.6466, Train: 1.1733, Val: 1.1555\n",
            "Epoch: 009, Loss: 1.3766, Train: 1.1082, Val: 1.1189\n",
            "Epoch: 010, Loss: 1.2282, Train: 1.4435, Val: 1.4613\n",
            "Epoch: 011, Loss: 2.0836, Train: 1.6668, Val: 1.6852\n",
            "Epoch: 012, Loss: 2.7784, Train: 1.7185, Val: 1.7368\n",
            "Epoch: 013, Loss: 2.9534, Train: 1.6296, Val: 1.6478\n",
            "Epoch: 014, Loss: 2.6556, Train: 1.4350, Val: 1.4526\n",
            "Epoch: 015, Loss: 2.0591, Train: 1.1917, Val: 1.2060\n",
            "Epoch: 016, Loss: 1.4202, Train: 1.0288, Val: 1.0324\n",
            "Epoch: 017, Loss: 1.0585, Train: 1.0987, Val: 1.0859\n",
            "Epoch: 018, Loss: 1.2072, Train: 1.2964, Val: 1.2732\n",
            "Epoch: 019, Loss: 1.6806, Train: 1.3737, Val: 1.3481\n",
            "Epoch: 020, Loss: 1.8876, Train: 1.2660, Val: 1.2442\n",
            "Epoch: 021, Loss: 1.6027, Train: 1.0929, Val: 1.0807\n",
            "Epoch: 022, Loss: 1.1945, Train: 1.0110, Val: 1.0115\n",
            "Epoch: 023, Loss: 1.0222, Train: 1.0541, Val: 1.0642\n",
            "Epoch: 024, Loss: 1.1112, Train: 1.1386, Val: 1.1532\n",
            "Epoch: 025, Loss: 1.2964, Train: 1.1924, Val: 1.2087\n",
            "Epoch: 026, Loss: 1.4218, Train: 1.1904, Val: 1.2068\n",
            "Epoch: 027, Loss: 1.4170, Train: 1.1377, Val: 1.1529\n",
            "Epoch: 028, Loss: 1.2943, Train: 1.0607, Val: 1.0728\n",
            "Epoch: 029, Loss: 1.1252, Train: 1.0036, Val: 1.0097\n",
            "Epoch: 030, Loss: 1.0071, Train: 1.0045, Val: 1.0028\n",
            "Epoch: 031, Loss: 1.0091, Train: 1.0529, Val: 1.0444\n",
            "Epoch: 032, Loss: 1.1087, Train: 1.0923, Val: 1.0805\n",
            "Epoch: 033, Loss: 1.1931, Train: 1.0818, Val: 1.0708\n",
            "Epoch: 034, Loss: 1.1703, Train: 1.0334, Val: 1.0268\n",
            "Epoch: 035, Loss: 1.0680, Train: 0.9917, Val: 0.9916\n",
            "Epoch: 036, Loss: 0.9834, Train: 0.9861, Val: 0.9924\n",
            "Epoch: 037, Loss: 0.9724, Train: 1.0078, Val: 1.0185\n",
            "Epoch: 038, Loss: 1.0156, Train: 1.0296, Val: 1.0426\n",
            "Epoch: 039, Loss: 1.0601, Train: 1.0328, Val: 1.0463\n",
            "Epoch: 040, Loss: 1.0667, Train: 1.0152, Val: 1.0277\n",
            "Epoch: 041, Loss: 1.0307, Train: 0.9889, Val: 0.9988\n",
            "Epoch: 042, Loss: 0.9780, Train: 0.9720, Val: 0.9780\n",
            "Epoch: 043, Loss: 0.9447, Train: 0.9746, Val: 0.9763\n",
            "Epoch: 044, Loss: 0.9499, Train: 0.9890, Val: 0.9872\n",
            "Epoch: 045, Loss: 0.9780, Train: 0.9965, Val: 0.9934\n",
            "Epoch: 046, Loss: 0.9929, Train: 0.9878, Val: 0.9858\n",
            "Epoch: 047, Loss: 0.9757, Train: 0.9708, Val: 0.9719\n",
            "Epoch: 048, Loss: 0.9424, Train: 0.9600, Val: 0.9649\n",
            "Epoch: 049, Loss: 0.9216, Train: 0.9612, Val: 0.9695\n",
            "Epoch: 050, Loss: 0.9239, Train: 0.9681, Val: 0.9786\n",
            "Epoch: 051, Loss: 0.9373, Train: 0.9712, Val: 0.9827\n",
            "Epoch: 052, Loss: 0.9433, Train: 0.9663, Val: 0.9774\n",
            "Epoch: 053, Loss: 0.9337, Train: 0.9565, Val: 0.9661\n",
            "Epoch: 054, Loss: 0.9150, Train: 0.9490, Val: 0.9563\n",
            "Epoch: 055, Loss: 0.9007, Train: 0.9482, Val: 0.9529\n",
            "Epoch: 056, Loss: 0.8991, Train: 0.9517, Val: 0.9544\n",
            "Epoch: 057, Loss: 0.9057, Train: 0.9529, Val: 0.9549\n",
            "Epoch: 058, Loss: 0.9081, Train: 0.9488, Val: 0.9515\n",
            "Epoch: 059, Loss: 0.9002, Train: 0.9422, Val: 0.9467\n",
            "Epoch: 060, Loss: 0.8877, Train: 0.9381, Val: 0.9449\n",
            "Epoch: 061, Loss: 0.8801, Train: 0.9381, Val: 0.9468\n",
            "Epoch: 062, Loss: 0.8800, Train: 0.9394, Val: 0.9494\n",
            "Epoch: 063, Loss: 0.8825, Train: 0.9386, Val: 0.9489\n",
            "Epoch: 064, Loss: 0.8810, Train: 0.9351, Val: 0.9448\n",
            "Epoch: 065, Loss: 0.8744, Train: 0.9309, Val: 0.9393\n",
            "Epoch: 066, Loss: 0.8666, Train: 0.9287, Val: 0.9355\n",
            "Epoch: 067, Loss: 0.8625, Train: 0.9287, Val: 0.9342\n",
            "Epoch: 068, Loss: 0.8625, Train: 0.9288, Val: 0.9335\n",
            "Epoch: 069, Loss: 0.8628, Train: 0.9272, Val: 0.9321\n",
            "Epoch: 070, Loss: 0.8597, Train: 0.9243, Val: 0.9301\n",
            "Epoch: 071, Loss: 0.8543, Train: 0.9219, Val: 0.9291\n",
            "Epoch: 072, Loss: 0.8499, Train: 0.9211, Val: 0.9295\n",
            "Epoch: 073, Loss: 0.8484, Train: 0.9210, Val: 0.9303\n",
            "Epoch: 074, Loss: 0.8483, Train: 0.9202, Val: 0.9297\n",
            "Epoch: 075, Loss: 0.8468, Train: 0.9184, Val: 0.9276\n",
            "Epoch: 076, Loss: 0.8435, Train: 0.9165, Val: 0.9248\n",
            "Epoch: 077, Loss: 0.8401, Train: 0.9155, Val: 0.9227\n",
            "Epoch: 078, Loss: 0.8381, Train: 0.9152, Val: 0.9217\n",
            "Epoch: 079, Loss: 0.8376, Train: 0.9148, Val: 0.9209\n",
            "Epoch: 080, Loss: 0.8368, Train: 0.9137, Val: 0.9201\n",
            "Epoch: 081, Loss: 0.8348, Train: 0.9123, Val: 0.9195\n",
            "Epoch: 082, Loss: 0.8323, Train: 0.9114, Val: 0.9195\n",
            "Epoch: 083, Loss: 0.8307, Train: 0.9111, Val: 0.9199\n",
            "Epoch: 084, Loss: 0.8300, Train: 0.9107, Val: 0.9200\n",
            "Epoch: 085, Loss: 0.8294, Train: 0.9100, Val: 0.9193\n",
            "Epoch: 086, Loss: 0.8282, Train: 0.9091, Val: 0.9180\n",
            "Epoch: 087, Loss: 0.8265, Train: 0.9084, Val: 0.9167\n",
            "Epoch: 088, Loss: 0.8253, Train: 0.9081, Val: 0.9159\n",
            "Epoch: 089, Loss: 0.8247, Train: 0.9079, Val: 0.9154\n",
            "Epoch: 090, Loss: 0.8243, Train: 0.9074, Val: 0.9151\n",
            "Epoch: 091, Loss: 0.8234, Train: 0.9068, Val: 0.9149\n",
            "Epoch: 092, Loss: 0.8223, Train: 0.9063, Val: 0.9151\n",
            "Epoch: 093, Loss: 0.8214, Train: 0.9061, Val: 0.9154\n",
            "Epoch: 094, Loss: 0.8209, Train: 0.9058, Val: 0.9156\n",
            "Epoch: 095, Loss: 0.8205, Train: 0.9055, Val: 0.9153\n",
            "Epoch: 096, Loss: 0.8199, Train: 0.9050, Val: 0.9147\n",
            "Epoch: 097, Loss: 0.8191, Train: 0.9047, Val: 0.9140\n",
            "Epoch: 098, Loss: 0.8184, Train: 0.9044, Val: 0.9135\n",
            "Epoch: 099, Loss: 0.8180, Train: 0.9042, Val: 0.9133\n",
            "Epoch: 100, Loss: 0.8176, Train: 0.9039, Val: 0.9132\n",
            "Epoch: 101, Loss: 0.8170, Train: 0.9035, Val: 0.9133\n",
            "Epoch: 102, Loss: 0.8164, Train: 0.9032, Val: 0.9135\n",
            "Epoch: 103, Loss: 0.8158, Train: 0.9030, Val: 0.9137\n",
            "Epoch: 104, Loss: 0.8154, Train: 0.9028, Val: 0.9138\n",
            "Epoch: 105, Loss: 0.8150, Train: 0.9024, Val: 0.9136\n",
            "Epoch: 106, Loss: 0.8144, Train: 0.9021, Val: 0.9132\n",
            "Epoch: 107, Loss: 0.8139, Train: 0.9019, Val: 0.9128\n",
            "Epoch: 108, Loss: 0.8134, Train: 0.9016, Val: 0.9126\n",
            "Epoch: 109, Loss: 0.8130, Train: 0.9014, Val: 0.9125\n",
            "Epoch: 110, Loss: 0.8125, Train: 0.9011, Val: 0.9125\n",
            "Epoch: 111, Loss: 0.8120, Train: 0.9008, Val: 0.9126\n",
            "Epoch: 112, Loss: 0.8114, Train: 0.9005, Val: 0.9128\n",
            "Epoch: 113, Loss: 0.8110, Train: 0.9003, Val: 0.9128\n",
            "Epoch: 114, Loss: 0.8105, Train: 0.9000, Val: 0.9128\n",
            "Epoch: 115, Loss: 0.8100, Train: 0.8997, Val: 0.9126\n",
            "Epoch: 116, Loss: 0.8095, Train: 0.8994, Val: 0.9123\n",
            "Epoch: 117, Loss: 0.8090, Train: 0.8992, Val: 0.9121\n",
            "Epoch: 118, Loss: 0.8085, Train: 0.8989, Val: 0.9120\n",
            "Epoch: 119, Loss: 0.8081, Train: 0.8986, Val: 0.9120\n",
            "Epoch: 120, Loss: 0.8076, Train: 0.8984, Val: 0.9120\n",
            "Epoch: 121, Loss: 0.8071, Train: 0.8981, Val: 0.9121\n",
            "Epoch: 122, Loss: 0.8066, Train: 0.8978, Val: 0.9121\n",
            "Epoch: 123, Loss: 0.8061, Train: 0.8975, Val: 0.9121\n",
            "Epoch: 124, Loss: 0.8056, Train: 0.8973, Val: 0.9119\n",
            "Epoch: 125, Loss: 0.8051, Train: 0.8970, Val: 0.9117\n",
            "Epoch: 126, Loss: 0.8046, Train: 0.8967, Val: 0.9116\n",
            "Epoch: 127, Loss: 0.8041, Train: 0.8964, Val: 0.9114\n",
            "Epoch: 128, Loss: 0.8036, Train: 0.8962, Val: 0.9114\n",
            "Epoch: 129, Loss: 0.8031, Train: 0.8959, Val: 0.9114\n",
            "Epoch: 130, Loss: 0.8026, Train: 0.8956, Val: 0.9114\n",
            "Epoch: 131, Loss: 0.8021, Train: 0.8953, Val: 0.9114\n",
            "Epoch: 132, Loss: 0.8016, Train: 0.8950, Val: 0.9113\n",
            "Epoch: 133, Loss: 0.8011, Train: 0.8947, Val: 0.9111\n",
            "Epoch: 134, Loss: 0.8006, Train: 0.8944, Val: 0.9110\n",
            "Epoch: 135, Loss: 0.8001, Train: 0.8941, Val: 0.9108\n",
            "Epoch: 136, Loss: 0.7995, Train: 0.8938, Val: 0.9107\n",
            "Epoch: 137, Loss: 0.7990, Train: 0.8935, Val: 0.9106\n",
            "Epoch: 138, Loss: 0.7985, Train: 0.8932, Val: 0.9105\n",
            "Epoch: 139, Loss: 0.7979, Train: 0.8929, Val: 0.9105\n",
            "Epoch: 140, Loss: 0.7974, Train: 0.8926, Val: 0.9104\n",
            "Epoch: 141, Loss: 0.7968, Train: 0.8923, Val: 0.9103\n",
            "Epoch: 142, Loss: 0.7963, Train: 0.8920, Val: 0.9102\n",
            "Epoch: 143, Loss: 0.7957, Train: 0.8917, Val: 0.9100\n",
            "Epoch: 144, Loss: 0.7952, Train: 0.8914, Val: 0.9098\n",
            "Epoch: 145, Loss: 0.7946, Train: 0.8911, Val: 0.9097\n",
            "Epoch: 146, Loss: 0.7941, Train: 0.8908, Val: 0.9096\n",
            "Epoch: 147, Loss: 0.7935, Train: 0.8904, Val: 0.9094\n",
            "Epoch: 148, Loss: 0.7929, Train: 0.8901, Val: 0.9094\n",
            "Epoch: 149, Loss: 0.7923, Train: 0.8898, Val: 0.9093\n",
            "Epoch: 150, Loss: 0.7918, Train: 0.8894, Val: 0.9092\n",
            "Epoch: 151, Loss: 0.7912, Train: 0.8891, Val: 0.9090\n",
            "Epoch: 152, Loss: 0.7906, Train: 0.8888, Val: 0.9089\n",
            "Epoch: 153, Loss: 0.7900, Train: 0.8884, Val: 0.9087\n",
            "Epoch: 154, Loss: 0.7894, Train: 0.8881, Val: 0.9086\n",
            "Epoch: 155, Loss: 0.7888, Train: 0.8878, Val: 0.9085\n",
            "Epoch: 156, Loss: 0.7882, Train: 0.8874, Val: 0.9084\n",
            "Epoch: 157, Loss: 0.7876, Train: 0.8871, Val: 0.9083\n",
            "Epoch: 158, Loss: 0.7870, Train: 0.8867, Val: 0.9082\n",
            "Epoch: 159, Loss: 0.7864, Train: 0.8864, Val: 0.9080\n",
            "Epoch: 160, Loss: 0.7858, Train: 0.8860, Val: 0.9079\n",
            "Epoch: 161, Loss: 0.7851, Train: 0.8857, Val: 0.9077\n",
            "Epoch: 162, Loss: 0.7845, Train: 0.8853, Val: 0.9076\n",
            "Epoch: 163, Loss: 0.7839, Train: 0.8850, Val: 0.9075\n",
            "Epoch: 164, Loss: 0.7833, Train: 0.8846, Val: 0.9074\n",
            "Epoch: 165, Loss: 0.7826, Train: 0.8843, Val: 0.9072\n",
            "Epoch: 166, Loss: 0.7820, Train: 0.8839, Val: 0.9071\n",
            "Epoch: 167, Loss: 0.7814, Train: 0.8835, Val: 0.9070\n",
            "Epoch: 168, Loss: 0.7807, Train: 0.8832, Val: 0.9069\n",
            "Epoch: 169, Loss: 0.7801, Train: 0.8828, Val: 0.9067\n",
            "Epoch: 170, Loss: 0.7794, Train: 0.8824, Val: 0.9066\n",
            "Epoch: 171, Loss: 0.7788, Train: 0.8821, Val: 0.9065\n",
            "Epoch: 172, Loss: 0.7782, Train: 0.8817, Val: 0.9064\n",
            "Epoch: 173, Loss: 0.7775, Train: 0.8813, Val: 0.9063\n",
            "Epoch: 174, Loss: 0.7769, Train: 0.8810, Val: 0.9061\n",
            "Epoch: 175, Loss: 0.7762, Train: 0.8806, Val: 0.9060\n",
            "Epoch: 176, Loss: 0.7755, Train: 0.8802, Val: 0.9059\n",
            "Epoch: 177, Loss: 0.7749, Train: 0.8798, Val: 0.9058\n",
            "Epoch: 178, Loss: 0.7742, Train: 0.8795, Val: 0.9057\n",
            "Epoch: 179, Loss: 0.7736, Train: 0.8791, Val: 0.9056\n",
            "Epoch: 180, Loss: 0.7729, Train: 0.8787, Val: 0.9055\n",
            "Epoch: 181, Loss: 0.7723, Train: 0.8783, Val: 0.9054\n",
            "Epoch: 182, Loss: 0.7716, Train: 0.8780, Val: 0.9053\n",
            "Epoch: 183, Loss: 0.7710, Train: 0.8776, Val: 0.9052\n",
            "Epoch: 184, Loss: 0.7703, Train: 0.8772, Val: 0.9051\n",
            "Epoch: 185, Loss: 0.7697, Train: 0.8768, Val: 0.9050\n",
            "Epoch: 186, Loss: 0.7690, Train: 0.8765, Val: 0.9049\n",
            "Epoch: 187, Loss: 0.7684, Train: 0.8761, Val: 0.9048\n",
            "Epoch: 188, Loss: 0.7677, Train: 0.8757, Val: 0.9047\n",
            "Epoch: 189, Loss: 0.7671, Train: 0.8754, Val: 0.9046\n",
            "Epoch: 190, Loss: 0.7664, Train: 0.8750, Val: 0.9046\n",
            "Epoch: 191, Loss: 0.7658, Train: 0.8746, Val: 0.9045\n",
            "Epoch: 192, Loss: 0.7651, Train: 0.8743, Val: 0.9044\n",
            "Epoch: 193, Loss: 0.7645, Train: 0.8739, Val: 0.9043\n",
            "Epoch: 194, Loss: 0.7639, Train: 0.8735, Val: 0.9043\n",
            "Epoch: 195, Loss: 0.7632, Train: 0.8732, Val: 0.9042\n",
            "Epoch: 196, Loss: 0.7626, Train: 0.8728, Val: 0.9042\n",
            "Epoch: 197, Loss: 0.7620, Train: 0.8725, Val: 0.9041\n",
            "Epoch: 198, Loss: 0.7614, Train: 0.8721, Val: 0.9041\n",
            "Epoch: 199, Loss: 0.7608, Train: 0.8718, Val: 0.9040\n",
            "Epoch: 200, Loss: 0.7602, Train: 0.8714, Val: 0.9040\n",
            "Epoch: 201, Loss: 0.7596, Train: 0.8711, Val: 0.9040\n",
            "Epoch: 202, Loss: 0.7590, Train: 0.8707, Val: 0.9039\n",
            "Epoch: 203, Loss: 0.7584, Train: 0.8704, Val: 0.9039\n",
            "Epoch: 204, Loss: 0.7578, Train: 0.8701, Val: 0.9039\n",
            "Epoch: 205, Loss: 0.7572, Train: 0.8697, Val: 0.9039\n",
            "Epoch: 206, Loss: 0.7567, Train: 0.8694, Val: 0.9038\n",
            "Epoch: 207, Loss: 0.7561, Train: 0.8691, Val: 0.9038\n",
            "Epoch: 208, Loss: 0.7555, Train: 0.8688, Val: 0.9038\n",
            "Epoch: 209, Loss: 0.7550, Train: 0.8685, Val: 0.9038\n",
            "Epoch: 210, Loss: 0.7545, Train: 0.8682, Val: 0.9038\n",
            "Epoch: 211, Loss: 0.7539, Train: 0.8679, Val: 0.9038\n",
            "Epoch: 212, Loss: 0.7534, Train: 0.8676, Val: 0.9038\n",
            "Epoch: 213, Loss: 0.7529, Train: 0.8673, Val: 0.9039\n",
            "Epoch: 214, Loss: 0.7524, Train: 0.8670, Val: 0.9039\n",
            "Epoch: 215, Loss: 0.7519, Train: 0.8667, Val: 0.9039\n",
            "Epoch: 216, Loss: 0.7514, Train: 0.8664, Val: 0.9039\n",
            "Epoch: 217, Loss: 0.7509, Train: 0.8661, Val: 0.9040\n",
            "Epoch: 218, Loss: 0.7504, Train: 0.8659, Val: 0.9040\n",
            "Epoch: 219, Loss: 0.7500, Train: 0.8656, Val: 0.9040\n",
            "Epoch: 220, Loss: 0.7495, Train: 0.8653, Val: 0.9041\n",
            "Epoch: 221, Loss: 0.7491, Train: 0.8651, Val: 0.9041\n",
            "Epoch: 222, Loss: 0.7486, Train: 0.8648, Val: 0.9042\n",
            "Epoch: 223, Loss: 0.7482, Train: 0.8646, Val: 0.9042\n",
            "Epoch: 224, Loss: 0.7478, Train: 0.8643, Val: 0.9043\n",
            "Epoch: 225, Loss: 0.7474, Train: 0.8641, Val: 0.9043\n",
            "Epoch: 226, Loss: 0.7470, Train: 0.8639, Val: 0.9044\n",
            "Epoch: 227, Loss: 0.7466, Train: 0.8636, Val: 0.9044\n",
            "Epoch: 228, Loss: 0.7462, Train: 0.8634, Val: 0.9045\n",
            "Epoch: 229, Loss: 0.7458, Train: 0.8632, Val: 0.9045\n",
            "Epoch: 230, Loss: 0.7454, Train: 0.8630, Val: 0.9046\n",
            "Epoch: 231, Loss: 0.7451, Train: 0.8628, Val: 0.9047\n",
            "Epoch: 232, Loss: 0.7447, Train: 0.8626, Val: 0.9047\n",
            "Epoch: 233, Loss: 0.7444, Train: 0.8624, Val: 0.9048\n",
            "Epoch: 234, Loss: 0.7440, Train: 0.8622, Val: 0.9048\n",
            "Epoch: 235, Loss: 0.7437, Train: 0.8620, Val: 0.9049\n",
            "Epoch: 236, Loss: 0.7434, Train: 0.8618, Val: 0.9050\n",
            "Epoch: 237, Loss: 0.7431, Train: 0.8616, Val: 0.9050\n",
            "Epoch: 238, Loss: 0.7428, Train: 0.8615, Val: 0.9051\n",
            "Epoch: 239, Loss: 0.7425, Train: 0.8613, Val: 0.9051\n",
            "Epoch: 240, Loss: 0.7422, Train: 0.8611, Val: 0.9052\n",
            "Epoch: 241, Loss: 0.7419, Train: 0.8610, Val: 0.9053\n",
            "Epoch: 242, Loss: 0.7416, Train: 0.8608, Val: 0.9053\n",
            "Epoch: 243, Loss: 0.7414, Train: 0.8606, Val: 0.9054\n",
            "Epoch: 244, Loss: 0.7411, Train: 0.8605, Val: 0.9054\n",
            "Epoch: 245, Loss: 0.7408, Train: 0.8603, Val: 0.9055\n",
            "Epoch: 246, Loss: 0.7406, Train: 0.8602, Val: 0.9055\n",
            "Epoch: 247, Loss: 0.7403, Train: 0.8600, Val: 0.9056\n",
            "Epoch: 248, Loss: 0.7401, Train: 0.8599, Val: 0.9056\n",
            "Epoch: 249, Loss: 0.7398, Train: 0.8598, Val: 0.9057\n",
            "Epoch: 250, Loss: 0.7396, Train: 0.8596, Val: 0.9057\n",
            "Epoch: 251, Loss: 0.7394, Train: 0.8595, Val: 0.9057\n",
            "Epoch: 252, Loss: 0.7392, Train: 0.8594, Val: 0.9058\n",
            "Epoch: 253, Loss: 0.7389, Train: 0.8592, Val: 0.9058\n",
            "Epoch: 254, Loss: 0.7387, Train: 0.8591, Val: 0.9058\n",
            "Epoch: 255, Loss: 0.7385, Train: 0.8590, Val: 0.9058\n",
            "Epoch: 256, Loss: 0.7383, Train: 0.8589, Val: 0.9059\n",
            "Epoch: 257, Loss: 0.7381, Train: 0.8588, Val: 0.9059\n",
            "Epoch: 258, Loss: 0.7379, Train: 0.8586, Val: 0.9059\n",
            "Epoch: 259, Loss: 0.7377, Train: 0.8585, Val: 0.9060\n",
            "Epoch: 260, Loss: 0.7375, Train: 0.8584, Val: 0.9060\n",
            "Epoch: 261, Loss: 0.7373, Train: 0.8583, Val: 0.9060\n",
            "Epoch: 262, Loss: 0.7371, Train: 0.8582, Val: 0.9060\n",
            "Epoch: 263, Loss: 0.7370, Train: 0.8581, Val: 0.9060\n",
            "Epoch: 264, Loss: 0.7368, Train: 0.8580, Val: 0.9060\n",
            "Epoch: 265, Loss: 0.7366, Train: 0.8579, Val: 0.9061\n",
            "Epoch: 266, Loss: 0.7364, Train: 0.8578, Val: 0.9061\n",
            "Epoch: 267, Loss: 0.7363, Train: 0.8577, Val: 0.9061\n",
            "Epoch: 268, Loss: 0.7361, Train: 0.8576, Val: 0.9061\n",
            "Epoch: 269, Loss: 0.7359, Train: 0.8575, Val: 0.9061\n",
            "Epoch: 270, Loss: 0.7358, Train: 0.8574, Val: 0.9061\n",
            "Epoch: 271, Loss: 0.7356, Train: 0.8573, Val: 0.9061\n",
            "Epoch: 272, Loss: 0.7355, Train: 0.8572, Val: 0.9061\n",
            "Epoch: 273, Loss: 0.7353, Train: 0.8571, Val: 0.9061\n",
            "Epoch: 274, Loss: 0.7351, Train: 0.8571, Val: 0.9061\n",
            "Epoch: 275, Loss: 0.7350, Train: 0.8570, Val: 0.9061\n",
            "Epoch: 276, Loss: 0.7348, Train: 0.8569, Val: 0.9061\n",
            "Epoch: 277, Loss: 0.7347, Train: 0.8568, Val: 0.9061\n",
            "Epoch: 278, Loss: 0.7346, Train: 0.8567, Val: 0.9061\n",
            "Epoch: 279, Loss: 0.7344, Train: 0.8566, Val: 0.9061\n",
            "Epoch: 280, Loss: 0.7343, Train: 0.8566, Val: 0.9061\n",
            "Epoch: 281, Loss: 0.7341, Train: 0.8565, Val: 0.9061\n",
            "Epoch: 282, Loss: 0.7340, Train: 0.8564, Val: 0.9061\n",
            "Epoch: 283, Loss: 0.7339, Train: 0.8563, Val: 0.9061\n",
            "Epoch: 284, Loss: 0.7337, Train: 0.8562, Val: 0.9061\n",
            "Epoch: 285, Loss: 0.7336, Train: 0.8562, Val: 0.9061\n",
            "Epoch: 286, Loss: 0.7335, Train: 0.8561, Val: 0.9061\n",
            "Epoch: 287, Loss: 0.7333, Train: 0.8560, Val: 0.9060\n",
            "Epoch: 288, Loss: 0.7332, Train: 0.8559, Val: 0.9060\n",
            "Epoch: 289, Loss: 0.7331, Train: 0.8559, Val: 0.9060\n",
            "Epoch: 290, Loss: 0.7330, Train: 0.8558, Val: 0.9060\n",
            "Epoch: 291, Loss: 0.7328, Train: 0.8557, Val: 0.9060\n",
            "Epoch: 292, Loss: 0.7327, Train: 0.8557, Val: 0.9060\n",
            "Epoch: 293, Loss: 0.7326, Train: 0.8556, Val: 0.9060\n",
            "Epoch: 294, Loss: 0.7325, Train: 0.8555, Val: 0.9060\n",
            "Epoch: 295, Loss: 0.7324, Train: 0.8554, Val: 0.9060\n",
            "Epoch: 296, Loss: 0.7322, Train: 0.8554, Val: 0.9060\n",
            "Epoch: 297, Loss: 0.7321, Train: 0.8553, Val: 0.9059\n",
            "Epoch: 298, Loss: 0.7320, Train: 0.8552, Val: 0.9059\n",
            "Epoch: 299, Loss: 0.7319, Train: 0.8552, Val: 0.9059\n",
            "Epoch: 300, Loss: 0.7318, Train: 0.8551, Val: 0.9059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "From the validation results, our model can generalize well to unseen data. The val RMSE is should be around 0.9, meaning that, on average our model is off by 0.9 stars. We can now evaluate our model on the test set and take a closer look into the predictions."
      ],
      "metadata": {
        "id": "EGP6RiiZJtU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    test_data = test_data.to(device)\n",
        "    pred = model(test_data.x_dict, test_data.edge_index_dict,\n",
        "                 test_data['user', 'movie'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=5)\n",
        "    target = test_data['user', 'movie'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    print(f'Test RMSE: {rmse:.4f}')\n",
        "\n",
        "userId = test_data['user', 'movie'].edge_label_index[0].cpu().numpy()\n",
        "movieId = test_data['user', 'movie'].edge_label_index[1].cpu().numpy()\n",
        "pred = pred.cpu().numpy()\n",
        "target = target.cpu().numpy()\n",
        "\n",
        "print(pd.DataFrame({'userId': userId, 'movieId': movieId, 'rating': pred, 'target': target}))"
      ],
      "metadata": {
        "id": "QT_NONRIJwE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a745d24-7369-462f-b8c3-7eba4f115504"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 0.9099\n",
            "       userId  movieId    rating  target\n",
            "0         110     2942  2.890016     2.0\n",
            "1         238     1028  4.205475     4.0\n",
            "2         445      464  2.855034     1.0\n",
            "3          27     2380  2.291777     3.5\n",
            "4          18     1673  1.976989     2.0\n",
            "...       ...      ...       ...     ...\n",
            "10079     419     7679  2.463532     3.0\n",
            "10080      56     2172  3.358167     1.0\n",
            "10081     278     1347  3.580696     2.0\n",
            "10082     152      166  2.799996     0.5\n",
            "10083     598     2468  3.100357     4.0\n",
            "\n",
            "[10084 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_user_id['userId'] == our_user_id"
      ],
      "metadata": {
        "id": "baol94I0b6Uk",
        "outputId": "db44c17b-ba78-419c-d799-7b377a87d882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      False\n",
              "1      False\n",
              "2      False\n",
              "3      False\n",
              "4      False\n",
              "       ...  \n",
              "605    False\n",
              "606    False\n",
              "607    False\n",
              "608    False\n",
              "609    False\n",
              "Name: userId, Length: 610, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Movie recommendations\n",
        "\n",
        "We can now use the model to generate ratings for a movie we haven't seen.\n"
      ],
      "metadata": {
        "id": "mWH_UzPYF7_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your mappedUserId\n",
        "mapped_user_id = unique_user_id[unique_user_id['userId'] == our_user_id]['mappedUserId'].values[0]\n",
        "\n",
        "# Select movies that you haven't seen before\n",
        "movies_rated = ratings_df[ratings_df['mappedUserId'] == mapped_user_id]\n",
        "movies_not_rated = movies_df[~movies_df.index.isin(movies_rated['movieId'])]\n",
        "movies_not_rated = movies_not_rated.merge(unique_movie_id, on='movieId')\n",
        "movie = movies_not_rated.sample(1)\n",
        "\n",
        "print(f\"The movie we want to predict a raiting for is:  {movie['title'].item()}\")"
      ],
      "metadata": {
        "id": "5gp3hABvCoFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a611b19f-16b6-4a8e-ca76-d14b75d311ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie we want to predict a raiting for is:  Rough Night (2017)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_not_rated[movies_not_rated.title.str.contains('Toy Story')]"
      ],
      "metadata": {
        "id": "d5abe65Zd7FL",
        "outputId": "076603bb-01ce-48a4-d916-9000a1c18644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      movieId               title  \\\n",
              "0           1    Toy Story (1995)   \n",
              "2350     3114  Toy Story 2 (1999)   \n",
              "7333    78499  Toy Story 3 (2010)   \n",
              "\n",
              "                                                genres  title_score  \\\n",
              "0          Adventure|Animation|Children|Comedy|Fantasy           14   \n",
              "2350       Adventure|Animation|Children|Comedy|Fantasy           13   \n",
              "7333  Adventure|Animation|Children|Comedy|Fantasy|IMAX           13   \n",
              "\n",
              "      mappedMovieId  \n",
              "0                 0  \n",
              "2350            735  \n",
              "7333           1133  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6e5dbea-4c7b-40f5-9d78-2035f69b7c00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>title_score</th>\n",
              "      <th>mappedMovieId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2350</th>\n",
              "      <td>3114</td>\n",
              "      <td>Toy Story 2 (1999)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "      <td>13</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7333</th>\n",
              "      <td>78499</td>\n",
              "      <td>Toy Story 3 (2010)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy|IMAX</td>\n",
              "      <td>13</td>\n",
              "      <td>1133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6e5dbea-4c7b-40f5-9d78-2035f69b7c00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6e5dbea-4c7b-40f5-9d78-2035f69b7c00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6e5dbea-4c7b-40f5-9d78-2035f69b7c00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-65417096-bc6f-4c7d-8ca6-7204b23e11ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65417096-bc6f-4c7d-8ca6-7204b23e11ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-65417096-bc6f-4c7d-8ca6-7204b23e11ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XK4uWO_edoXU",
        "outputId": "371a7c0a-05f8-48b6-d5e3-b0177c64d0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     movieId                  title                  genres  title_score  \\\n",
              "825     1089  Reservoir Dogs (1992)  Crime|Mystery|Thriller           18   \n",
              "\n",
              "     mappedMovieId  \n",
              "825             62  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-786ff9f3-b481-4627-9d32-5802f79da14f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>title_score</th>\n",
              "      <th>mappedMovieId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>1089</td>\n",
              "      <td>Reservoir Dogs (1992)</td>\n",
              "      <td>Crime|Mystery|Thriller</td>\n",
              "      <td>18</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-786ff9f3-b481-4627-9d32-5802f79da14f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-786ff9f3-b481-4627-9d32-5802f79da14f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-786ff9f3-b481-4627-9d32-5802f79da14f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "movie = movies_not_rated.query(\"movieId == 3114\")\n",
        "\n",
        "\n",
        "# Create new `edge_label_index` between the user and the movie\n",
        "edge_label_index = torch.tensor([\n",
        "    mapped_user_id,\n",
        "    movie.mappedMovieId.item()])\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_data.to(device)\n",
        "    pred = model(test_data.x_dict, test_data.edge_index_ict, edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=5).detach().cpu().numpy()\n",
        "pred.item()"
      ],
      "metadata": {
        "id": "XYe9poFGEig6",
        "outputId": "fe75e418-55a6-441a-92cc-49ef5650c0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-3beb74fd5d24>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_ict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_label_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/hetero_data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dict$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         raise AttributeError(f\"'{self.__class__.__name__}' has no \"\n\u001b[0m\u001b[1;32m    160\u001b[0m                              f\"attribute '{key}'\")\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'HeteroData' has no attribute 'edge_index_ict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GN5uxt-CD1lV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explaining the Predictions\n",
        "\n",
        "PyTorch Geometric also provides a way to explain the predictions of a GNN. Let's check which movie ratings have influenced this prediction the most.\n",
        "\n",
        "We will use the [captum](https://captum.ai/) library to explain the predictions."
      ],
      "metadata": {
        "id": "TyhTL520KFwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.explain import Explainer, CaptumExplainer\n",
        "\n",
        "explainer = Explainer(\n",
        "    model=model,\n",
        "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
        "    explanation_type='model',\n",
        "    model_config=dict(\n",
        "        mode='regression',\n",
        "        task_level='edge',\n",
        "        return_type='raw',\n",
        "    ),\n",
        "    node_mask_type=None,\n",
        "    edge_mask_type='object',\n",
        ")\n",
        "\n",
        "explanation = explainer(\n",
        "    test_data.x_dict, test_data.edge_index_dict, index=0,\n",
        "    edge_label_index=edge_label_index).cpu().detach()\n",
        "explanation"
      ],
      "metadata": {
        "id": "i1fe7gcrPNo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8728af-e107-41fd-c63c-5a11bc701eed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroExplanation(\n",
              "  prediction=[1],\n",
              "  target=[1],\n",
              "  index=[1],\n",
              "  edge_label_index=[2],\n",
              "  user={ x=[611, 611] },\n",
              "  movie={ x=[9742, 404] },\n",
              "  (user, rates, movie)={\n",
              "    edge_mask=[90757],\n",
              "    edge_index=[2, 90757],\n",
              "  },\n",
              "  (movie, rev_rates, user)={\n",
              "    edge_mask=[90757],\n",
              "    edge_index=[2, 90757],\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User to movie link + attribution\n",
        "user_to_movie = explanation['user', 'movie'].edge_index.numpy().T\n",
        "user_to_movie_attr = explanation['user', 'movie'].edge_mask.numpy().T\n",
        "user_to_movie_df = pd.DataFrame(\n",
        "    np.hstack([user_to_movie, user_to_movie_attr.reshape(-1,1)]),\n",
        "    columns = ['mappedUserId', 'mappedMovieId', 'attr']\n",
        ")\n",
        "\n",
        "# Movie to user link + attribution\n",
        "movie_to_user = explanation['movie', 'user'].edge_index.numpy().T\n",
        "movie_to_user_attr = explanation[ 'movie', 'user'].edge_mask.numpy().T\n",
        "movie_to_user_df = pd.DataFrame(\n",
        "    np.hstack([movie_to_user, movie_to_user_attr.reshape(-1,1)]),\n",
        "    columns = ['mappedMovieId', 'mappedUserId','attr']\n",
        ")\n",
        "explanation_df = pd.concat([user_to_movie_df, movie_to_user_df])\n",
        "explanation_df[[\"mappedUserId\", \"mappedMovieId\"]] = explanation_df[[\"mappedUserId\", \"mappedMovieId\"]].astype(int)\n",
        "\n",
        "print(f\"Attribtion for all edges towards prediction of movie rating of movie:\\n {movie['title'].item()}\")\n",
        "print(\"==========================================================================================\")\n",
        "print(explanation_df.sort_values(by='attr'))"
      ],
      "metadata": {
        "id": "3YIoR6LOGLa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c2ba27-2220-4fdf-9260-fe7d0cc5e379"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attribtion for all edges towards prediction of movie rating of movie:\n",
            " Rough Night (2017)\n",
            "==========================================================================================\n",
            "       mappedUserId  mappedMovieId      attr\n",
            "10256           359            987 -0.000077\n",
            "24919           381            987 -0.000077\n",
            "78676           381            238 -0.000070\n",
            "73191           162            987 -0.000070\n",
            "60852            81            987 -0.000069\n",
            "...             ...            ...       ...\n",
            "18433           610            987  0.012246\n",
            "1061            610            926  0.016858\n",
            "53427           610            238  0.019989\n",
            "5203            610             26  0.021320\n",
            "87166           490           4642  0.286938\n",
            "\n",
            "[181514 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select links that connect to our user\n",
        "explanation_df = explanation_df[explanation_df['mappedUserId'] == mapped_user_id]\n",
        "\n",
        "# We group the attribution scores by movie\n",
        "explanation_df = explanation_df.groupby('mappedMovieId').sum()\n",
        "\n",
        "# Merge with movies_df to receive title\n",
        "# But first, we need to add the original id\n",
        "explanation_df = explanation_df.merge(unique_movie_id, on='mappedMovieId')\n",
        "explanation_df = explanation_df.merge(movies_df, on='movieId')\n",
        "\n",
        "pd.options.display.float_format = \"{:,.9f}\".format\n",
        "\n",
        "print(\"Top movies that influenced the prediction:\")\n",
        "print(\"==============================================\")\n",
        "print(explanation_df.sort_values(by='attr', ascending=False, key= lambda x: abs(x))[['title', 'attr']].head())"
      ],
      "metadata": {
        "id": "8yN6svXQKe7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97c75dd-453c-4817-e08c-0650cf23c0d7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top movies that influenced the prediction:\n",
            "==============================================\n",
            "                     title        attr\n",
            "0     Jurassic Park (1993) 0.021328844\n",
            "1  Dark Knight, The (2008) 0.020002849\n",
            "2            Avatar (2009) 0.016878687\n",
            "3           Titanic (1997) 0.012261876\n"
          ]
        }
      ]
    }
  ]
}